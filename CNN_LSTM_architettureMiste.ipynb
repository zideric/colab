{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_LSTM_architettureMiste.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOa9phv+gaQ3KYPmUQPgNia",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zideric/colab/blob/main/CNN_LSTM_architettureMiste.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "voIwIVm4EJJl"
      },
      "source": [
        "# CNN + LSTM con Keras\n",
        "proviamo a creare una rete neurale che combina uno stato convoluzionale con uno ricorrente per classificare le rencesioni di IMDB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d66piFAUEbi7"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.datasets import imdb\n",
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hh_qz5YmEtfs"
      },
      "source": [
        "## Caricamento e preprocessing del dataset\n",
        "carichiamo il dataset con Keras con le 10k parole piu comuni, poi tronchiamo le recenzioni a 500 con pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1KZIARvEqew",
        "outputId": "38e7c646-b35b-4fce-ac7a-1e6f258d9de4"
      },
      "source": [
        "num_words = 10000\n",
        "maxlen = 500\n",
        "\n",
        "(X_train, y_train),(X_test,y_test) = imdb.load_data(num_words=num_words)\n",
        "\n",
        "X_train = pad_sequences(X_train, maxlen=maxlen)\n",
        "X_test = pad_sequences(X_test, maxlen=maxlen)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBKVnjyZFVpo"
      },
      "source": [
        "## Creazione del modello\n",
        "\n",
        "### Modello1: Rete convoluzionale"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oaaVfC9kFUoj",
        "outputId": "7587fb40-c5ec-41d7-f387-033a2f96a156"
      },
      "source": [
        "from keras.layers import Embedding, LSTM, Flatten\n",
        "from keras.layers.convolutional import Conv1D, MaxPooling1D\n",
        "\n",
        "model=Sequential()\n",
        "\n",
        "model.add(Embedding(num_words, 50, input_length=maxlen))\n",
        "model.add(Conv1D(filters=32, kernel_size=3,padding='same',activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, 500, 50)           500000    \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 500, 32)           4832      \n",
            "_________________________________________________________________\n",
            "max_pooling1d_3 (MaxPooling1 (None, 250, 32)           0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 8000)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 8001      \n",
            "=================================================================\n",
            "Total params: 512,833\n",
            "Trainable params: 512,833\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Aqyfu6iGDHN",
        "outputId": "f77a86b2-ea54-41a3-f637-4b413eb97861"
      },
      "source": [
        "model.compile(loss='binary_crossentropy',optimizer='rmsprop',metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, batch_size=512,validation_split=0.2, epochs=5)\n",
        "model.evaluate(X_test,y_test)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "40/40 [==============================] - 17s 405ms/step - loss: 0.6851 - accuracy: 0.5438 - val_loss: 0.5720 - val_accuracy: 0.7052\n",
            "Epoch 2/10\n",
            "40/40 [==============================] - 16s 397ms/step - loss: 0.4749 - accuracy: 0.8108 - val_loss: 0.3626 - val_accuracy: 0.8440\n",
            "Epoch 3/10\n",
            "40/40 [==============================] - 16s 397ms/step - loss: 0.2905 - accuracy: 0.8869 - val_loss: 0.3556 - val_accuracy: 0.8504\n",
            "Epoch 4/10\n",
            "40/40 [==============================] - 16s 397ms/step - loss: 0.2251 - accuracy: 0.9152 - val_loss: 0.3291 - val_accuracy: 0.8614\n",
            "Epoch 5/10\n",
            "40/40 [==============================] - 16s 390ms/step - loss: 0.1845 - accuracy: 0.9294 - val_loss: 0.2643 - val_accuracy: 0.8918\n",
            "Epoch 6/10\n",
            "40/40 [==============================] - 16s 391ms/step - loss: 0.1580 - accuracy: 0.9415 - val_loss: 0.3342 - val_accuracy: 0.8740\n",
            "Epoch 7/10\n",
            "40/40 [==============================] - 16s 391ms/step - loss: 0.1339 - accuracy: 0.9530 - val_loss: 0.2884 - val_accuracy: 0.8936\n",
            "Epoch 8/10\n",
            "40/40 [==============================] - 16s 394ms/step - loss: 0.1166 - accuracy: 0.9587 - val_loss: 0.3003 - val_accuracy: 0.8926\n",
            "Epoch 9/10\n",
            "40/40 [==============================] - 16s 396ms/step - loss: 0.1025 - accuracy: 0.9653 - val_loss: 0.3196 - val_accuracy: 0.8860\n",
            "Epoch 10/10\n",
            "40/40 [==============================] - 16s 395ms/step - loss: 0.0884 - accuracy: 0.9706 - val_loss: 0.3572 - val_accuracy: 0.8784\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.3788 - accuracy: 0.8681\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.37882164120674133, 0.868120014667511]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8v2FvKpEJTC_"
      },
      "source": [
        "### Modello2: da ricorrente a convoluzionale"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvPuxLq-GcIb",
        "outputId": "d4ed825d-fa95-4fbd-b256-f8177edf776e"
      },
      "source": [
        "model=Sequential()\n",
        "\n",
        "model.add(Embedding(num_words, 50, input_length=maxlen))\n",
        "model.add(LSTM(32, dropout=0.4, return_sequences=True))\n",
        "model.add(Conv1D(filters=32, kernel_size=3,padding='same',activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_4 (Embedding)      (None, 500, 50)           500000    \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 500, 32)           10624     \n",
            "_________________________________________________________________\n",
            "conv1d_4 (Conv1D)            (None, 500, 32)           3104      \n",
            "_________________________________________________________________\n",
            "max_pooling1d_4 (MaxPooling1 (None, 250, 32)           0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 8000)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 8001      \n",
            "=================================================================\n",
            "Total params: 521,729\n",
            "Trainable params: 521,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTn1pSIXJt4N"
      },
      "source": [
        "compiliamo e addestriamo per 10 epoche"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZmBiaxDJqjj",
        "outputId": "e2498876-4009-496b-a350-6977e0889a17"
      },
      "source": [
        "model.compile(loss='binary_crossentropy',optimizer='rmsprop',metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, batch_size=512,validation_split=0.2, epochs=5)\n",
        "model.evaluate(X_test,y_test)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "40/40 [==============================] - 66s 2s/step - loss: 0.6613 - accuracy: 0.5772 - val_loss: 0.4519 - val_accuracy: 0.7998\n",
            "Epoch 2/10\n",
            "40/40 [==============================] - 65s 2s/step - loss: 0.3698 - accuracy: 0.8479 - val_loss: 0.3066 - val_accuracy: 0.8742\n",
            "Epoch 3/10\n",
            "40/40 [==============================] - 66s 2s/step - loss: 0.2854 - accuracy: 0.8854 - val_loss: 0.4981 - val_accuracy: 0.8296\n",
            "Epoch 4/10\n",
            "40/40 [==============================] - 64s 2s/step - loss: 0.3020 - accuracy: 0.8841 - val_loss: 0.2752 - val_accuracy: 0.8900\n",
            "Epoch 5/10\n",
            "40/40 [==============================] - 64s 2s/step - loss: 0.2040 - accuracy: 0.9227 - val_loss: 0.2778 - val_accuracy: 0.8912\n",
            "Epoch 6/10\n",
            "40/40 [==============================] - 65s 2s/step - loss: 0.1843 - accuracy: 0.9291 - val_loss: 0.3007 - val_accuracy: 0.8930\n",
            "Epoch 7/10\n",
            "40/40 [==============================] - 64s 2s/step - loss: 0.1781 - accuracy: 0.9333 - val_loss: 0.4032 - val_accuracy: 0.8556\n",
            "Epoch 8/10\n",
            "40/40 [==============================] - 66s 2s/step - loss: 0.1548 - accuracy: 0.9372 - val_loss: 0.3322 - val_accuracy: 0.8918\n",
            "Epoch 9/10\n",
            "40/40 [==============================] - 65s 2s/step - loss: 0.1363 - accuracy: 0.9478 - val_loss: 0.4350 - val_accuracy: 0.8658\n",
            "Epoch 10/10\n",
            "40/40 [==============================] - 65s 2s/step - loss: 0.1319 - accuracy: 0.9453 - val_loss: 0.3244 - val_accuracy: 0.8898\n",
            "782/782 [==============================] - 40s 51ms/step - loss: 0.3463 - accuracy: 0.8764\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.34626418352127075, 0.8763599991798401]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLXwHHF3TDz7"
      },
      "source": [
        "### Modello3: da convoluzionale a ricorrente\n",
        "L'archietettura della rete sarà la seguente:\n",
        "* primo strato embedding\n",
        "* secondo strato convoluzionale con 32 filtri di dimensione 3*3\n",
        "* terzo strato riduce la dimensione delle features map con il max pooling\n",
        "* quarto strato è ricorrente LSTM, per ridurre overfitting eseguiamo dropout sull'input del 40% dei nodi\n",
        "* quinto strato output della rete\n",
        "\n",
        "usaimo il Conv1D perche in questo caso non siamo di fronte ad un tensore ma ad una semplice matrice (tensore sono piu matrici sovrapposte)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "liqB_INUJ2wA",
        "outputId": "3cf89a4b-ddb3-4793-ebe7-4349ffe3e588"
      },
      "source": [
        "model=Sequential()\n",
        "\n",
        "model.add(Embedding(num_words, 50, input_length=maxlen))\n",
        "model.add(Conv1D(filters=32, kernel_size=3,padding='same',activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(LSTM(32, dropout=0.4))\n",
        "# model.add(Flatten()) non serve perche output di lstm è già Flat se non settato return_sequences = True\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_5 (Embedding)      (None, 500, 50)           500000    \n",
            "_________________________________________________________________\n",
            "conv1d_5 (Conv1D)            (None, 500, 32)           4832      \n",
            "_________________________________________________________________\n",
            "max_pooling1d_5 (MaxPooling1 (None, 250, 32)           0         \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 32)                8320      \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 513,185\n",
            "Trainable params: 513,185\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RgRdPje3UcB7"
      },
      "source": [
        "compiliamo ed eseguiamo l'addestramento\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otitAU8lUTLG",
        "outputId": "454f6089-96c4-4f46-8566-2630cb350c32"
      },
      "source": [
        "model.compile(loss='binary_crossentropy',optimizer='rmsprop',metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, batch_size=512,validation_split=0.2, epochs=5)\n",
        "model.evaluate(X_test,y_test)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "40/40 [==============================] - 40s 935ms/step - loss: 0.6676 - accuracy: 0.5984 - val_loss: 0.4801 - val_accuracy: 0.7880\n",
            "Epoch 2/5\n",
            "40/40 [==============================] - 37s 927ms/step - loss: 0.4062 - accuracy: 0.8366 - val_loss: 0.7757 - val_accuracy: 0.6474\n",
            "Epoch 3/5\n",
            "40/40 [==============================] - 36s 910ms/step - loss: 0.3283 - accuracy: 0.8721 - val_loss: 0.7532 - val_accuracy: 0.6854\n",
            "Epoch 4/5\n",
            "40/40 [==============================] - 36s 909ms/step - loss: 0.2785 - accuracy: 0.8973 - val_loss: 0.2808 - val_accuracy: 0.8840\n",
            "Epoch 5/5\n",
            "40/40 [==============================] - 36s 913ms/step - loss: 0.2120 - accuracy: 0.9205 - val_loss: 0.3002 - val_accuracy: 0.8814\n",
            "782/782 [==============================] - 24s 31ms/step - loss: 0.3109 - accuracy: 0.8738\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3109285533428192, 0.8737599849700928]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JU3JrI-DVYEO"
      },
      "source": [
        "l'approccio ibrido, con diverse sperimentazioni, porta a risultati migliori"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rbLoympUbZC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}