{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Gradient Descent.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNQ11KGtQ+Ohhb82uc+Ol1R",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zideric/colab/blob/main/Gradient_Descent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_g_zsZKB-0qF"
      },
      "source": [
        "# Stochastic, Mini batch e Full batch Gradient Descent\n",
        "\n",
        "vediamo le tre varianti dell'algoritmo di ottimizzazione\n",
        "\n",
        "* **Full Batch:** utilizza tutti gli esempi per correggere i coefficienti\n",
        "* **Stochasti:** un solo esempio per volta per correggere i coefficienti\n",
        "* **Mini Batch:** utilizza un determinato numero di esempio per volta per correggere i coefficienti\n",
        "\n",
        "utilizziamo il [Fashion MNIST dataset](https://github.com/zalandoresearch/fashion-mnist), contiene capi di abbigliamento corrrettamente classificati, creato da Zalando\n",
        "\n",
        "Importiamo i moduli"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKQFRiVI_d1g"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "from time import time\n",
        "\n",
        "#definisco la funzione di profession AI per poter riprodurre i risultati in questo notebook\n",
        "\n",
        "def set_seed(seed):\n",
        "    from os import environ\n",
        "    environ[\"PYTHONHASHSEED\"] = '0'\n",
        "    environ[\"CUDA_VISIBLE_DEVICES\"]='-1'\n",
        "    environ[\"TF_CUDNN_USE_AUTOTUNE\"] ='0'\n",
        "\n",
        "    from numpy.random import seed as np_seed\n",
        "    np_seed(seed)\n",
        "    import random\n",
        "    random.seed(seed)\n",
        "    from tensorflow import set_random_seed\n",
        "    set_random_seed(seed)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTeGA9WxACYW"
      },
      "source": [
        "## Preparazione dei dati\n",
        "\n",
        "carichiamo il dataset direttamente da Keras."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lq-VAny2_82r",
        "outputId": "b52e41cd-c27c-4a47-e2a3-46a3c510409a"
      },
      "source": [
        "from keras.datasets import fashion_mnist\n",
        "\n",
        "labels = [\"T-shirt/top\",\"Pantalone\",\"Pullover\",\"Vestito\",\"Cappotto\",\"Sandalo\",\"Maglietta\",\"Sneaker\",\"Borsa\",\"Stivaletto\"]\n",
        "\n",
        "(X_train, y_train),(X_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "print(\"Numero di proprieta: \" + str(X_train.shape[1]))\n",
        "print(\"Esempi di training: \" + str(X_train.shape[0]))\n",
        "print(\"Esempi di test: \" + str(X_test.shape[0]))\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "Numero di proprieta: 28\n",
            "Esempi di training: 60000\n",
            "Esempi di test: 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHSZ0U4hBA-5"
      },
      "source": [
        "l'immagine è rappresentata da una matrice di 28*28 pixel\n",
        "visualizziamone una"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "NrkL27g9AiA2",
        "outputId": "595c9acf-20a8-4456-bdf4-119bc90afd41"
      },
      "source": [
        "plt.axis(\"off\") \n",
        "plt.imshow(X_train[1],cmap=\"gray\")\n",
        "print(\"L'immagine raffigura un/o %s\" % labels[y_train[1]])\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "L'immagine raffigura un/o T-shirt/top\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6GyE-VhB07a"
      },
      "source": [
        "visto che ogni singolo elemmento (osservazione) è una matrice 28*28 dobbiamo convertire questa matrice in un singolo vettore da dare in input al modello. Usiamo reshape (al contrario del solito per visualizzare immagine)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgRxKrQzCR8B",
        "outputId": "95c4d840-c74f-449b-e903-bbce01ca8d98"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3_gjf6RAurb",
        "outputId": "4e06e0e2-5b03-4175-9f69-9a1502037087"
      },
      "source": [
        "X_train = X_train.reshape(X_train.shape[0],28*28)\n",
        "X_test = X_test.reshape(X_test.shape[0],28*28)\n",
        "\n",
        "X_train.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 784)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZ03ecBcCgwV"
      },
      "source": [
        "standardizziamo i valori, anche in questo caso ci basta dividere ogni valore per 255 visto che 255 è il valore massimo e 0 il valore minimo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hiqghcJcBolV"
      },
      "source": [
        "X_train = X_train/255\n",
        "X_test = X_test/255"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9POewYntCv2m"
      },
      "source": [
        "Gli array con i target contengono un valore numerico che va da 0 a 9, questo numero rappresenta la categoria di appartenenza del prodotto.\n",
        "per poter eseguire la classificazione multiclasse dobbiamo crare 10 variabili dumm per ogni osservaizone, una per ogni classe, quella con il valore 1 sarà la classe identificata dal modelllo (creiamo un array di 10 elementi per ogni target)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5uiPbV5Csep"
      },
      "source": [
        "from keras.utils import to_categorical\n",
        "\n",
        "num_classes = 10\n",
        "\n",
        "y_train_dummy = to_categorical(y_train, num_classes)\n",
        "y_test_dumyy = to_categorical(y_test, num_classes)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxGVlszjDSwk"
      },
      "source": [
        "## Full batch\n",
        "\n",
        "creiamo il modello, usiamo la stessa architettura del notebook precedente"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8PW3UaqFcF_"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "from time import time\n",
        "\n",
        "#definisco la funzione di profession AI per poter riprodurre i risultati in questo notebook\n",
        "\n",
        "def set_seed(seed):\n",
        "    from os import environ\n",
        "    environ[\"PYTHONHASHSEED\"] = '0'\n",
        "    environ[\"CUDA_VISIBLE_DEVICES\"]='-1'\n",
        "    environ[\"TF_CUDNN_USE_AUTOTUNE\"] ='0'\n",
        "\n",
        "    from numpy.random import seed as np_seed\n",
        "    np_seed(seed)\n",
        "    import random\n",
        "    random.seed(seed)\n",
        "    from tensorflow import set_random_seed\n",
        "    set_random_seed(seed)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1qodKfSFbKQ"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "from time import time\n",
        "\n",
        "#definisco la funzione di profession AI per poter riprodurre i risultati in questo notebook\n",
        "\n",
        "def set_seed(seed):\n",
        "    from os import environ\n",
        "    environ[\"PYTHONHASHSEED\"] = '0'\n",
        "    environ[\"CUDA_VISIBLE_DEVICES\"]='-1'\n",
        "    environ[\"TF_CUDNN_USE_AUTOTUNE\"] ='0'\n",
        "\n",
        "    from numpy.random import seed as np_seed\n",
        "    np_seed(seed)\n",
        "    import random\n",
        "    random.seed(seed)\n",
        "    from tensorflow import set_random_seed\n",
        "    set_random_seed(seed)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcg6kXjTDQ0b"
      },
      "source": [
        "#set_seed(0)  #peer riprodurre i risultati come il corso\n",
        "import tensorflow\n",
        "tensorflow.random.set_seed(0\n",
        "                           )\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(512, activation='relu', input_dim=X_train.shape[1]))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(num_classes, activation='softmax')) #neurone di optput mettiamo softmax\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcik4eUrD1Hv",
        "outputId": "0474ba14-71d7-4d8b-c0ff-aa61045ddfc0"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 567,434\n",
            "Trainable params: 567,434\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uev83n3cD8xf"
      },
      "source": [
        "sono oltre mezzo milione di parametri. Utilizziamo il metodo compile per preparare il modello per l'addestramento. \n",
        "Come ottimizzatore usiamo sempre lo stochastic (sgd, vediamo perche bisogna specificare sempre questo anche se vogliamo full batch)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLrWIDTSD7V1"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='sgd',metrics=['accuracy'])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qyVLs_DpEao9"
      },
      "source": [
        "Adesso, per utilizzare il full batch gradient descent, non dobbiamo far altro che specificare all'interno del metodo fit che la dimensione di un batch deve essere pari al numero di osservazioni nel set di addestramento, in tal modo l'algoritmo di ottimizzazione utilizzerà un unico batch con tutte le osservazioni ad ogni iterazione del gradient descent.\n",
        "Per poter costruire un grafico della funzione di costo ad ogni epoca dobbiamo tener traccia di questi valori, per farlo dobbiamo definire un callback."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3CxiBoLEWqT",
        "outputId": "44d1ea8c-f6ec-4ebd-cb4d-5c1cf4e30d72"
      },
      "source": [
        "from keras.callbacks import History\n",
        "\n",
        "history = History()\n",
        "\n",
        "start_at = time()\n",
        "model.fit(X_train, y_train_dummy, epochs=10, batch_size=X_train.shape[0],callbacks=[history])\n",
        "exec_time= time()-start_at\n",
        "\n",
        "print(\"Tempo di addestramento: %d minuti e %d secondi\" % (exec_time/60, exec_time%60))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1/1 [==============================] - 4s 4s/step - loss: 2.4030 - accuracy: 0.0945\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 3s 3s/step - loss: 2.3737 - accuracy: 0.0919\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 3s 3s/step - loss: 2.3477 - accuracy: 0.0898\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 3s 3s/step - loss: 2.3245 - accuracy: 0.0915\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 3s 3s/step - loss: 2.3036 - accuracy: 0.0982\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 3s 3s/step - loss: 2.2844 - accuracy: 0.1115\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 3s 3s/step - loss: 2.2665 - accuracy: 0.1303\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 3s 3s/step - loss: 2.2497 - accuracy: 0.1525\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 3s 3s/step - loss: 2.2337 - accuracy: 0.1796\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 3s 3s/step - loss: 2.2183 - accuracy: 0.2095\n",
            "Tempo di addestramento: 0 minuti e 27 secondi\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6T6xXmDm3cBY"
      },
      "source": [
        "I risultati del modello sono piuttosto scarsi, perché le 100 epoche non erano sufficenti a portare alla convergenza, infatti con ulteriori epoche il modello avrebbe continuato a migliorare.\r\n",
        "Utilizziamo i valori della funzione di costo raccolti per visualizzare la sua variazione a ogni epoche su di un grafico."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 638
        },
        "id": "5Gj0ItsKE96v",
        "outputId": "a6d02c21-d82c-4534-fcfd-84f1e4d4b573"
      },
      "source": [
        "plt.figure(figsize=(14,10))\r\n",
        "plt.title(\"Full Batch Gradient Descent\")\r\n",
        "plt.xlabel(\"Epoca\")\r\n",
        "plt.ylabel(\"Log-Loss\")\r\n",
        "plt.plot(history.history['loss'])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f645d91cf50>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1008x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wRaCOOt53o_"
      },
      "source": [
        "come si puo osservare, l'errore del modello si è ridotto in maniera pulita senza oscillazioni\r\n",
        "\r\n",
        "## Stochastic Gradient Descent\r\n",
        "\r\n",
        "questo è l'estremo opposto, iniziamo ricostruendo il modello"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8wj__4k59ND"
      },
      "source": [
        "tensorflow.random.set_seed(0\r\n",
        "                          ) #per poter riprodurrer i risultati\r\n",
        "\r\n",
        "model = Sequential()\r\n",
        "model.add(Dense(512, activation='relu', input_dim=X_train.shape[1]))\r\n",
        "model.add(Dense(256, activation='relu'))\r\n",
        "model.add(Dense(128, activation='relu'))\r\n",
        "model.add(Dense(num_classes,activation='softmax'))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UeJiV9kh8uk5"
      },
      "source": [
        "abbiamo dovuto ricreare il modello altrimenti chiamando il metodo fit l'addestramento sarebbe ripartito da dove si era  fermato all'esecuzione precedente (quindi fino a dove aveva iniziato ad imparare) continuando a ottimizzare i coefficienti che aveva già trovato\r\n",
        "\r\n",
        "compiliamo il modello"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfKCHYCN8tN5"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',optimizer='sgd', metrics=['accuracy'])"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_flXpo09Fuy"
      },
      "source": [
        "Adesso, per utilizzare lo Stochastic Gradient Descent, impostiamo come dimensione del singolo batch 1, in modo tale da far utilizzare all'algoritmo di ottimizzazione un esempio per volta. Facendo questo il gradient descent ad ogni epoca viene eseguito un numero di volte pari al numero di esempi nel set di addestramento (nel nostro caso 60.000), ne segue che il completamento di un'epoca richiederà molto più tempo rispetto al full batch. Per questo motivo impostiamo il numero di epoche a 5."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "vypp3YN19FFH",
        "outputId": "49782933-b400-4edd-89ea-8951193c8013"
      },
      "source": [
        "start_at = time()\r\n",
        "model.fit(X_train, y_train_dummy, epochs=5, batch_size=1)\r\n",
        "exec_time = time()- start_at\r\n",
        "\r\n",
        "print(\"Tempo di addestramento: %d minuti e %d secondi\" % (exec_time/60, exec_time%60))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 122s 2ms/step - loss: 0.6336 - accuracy: 0.7683\n",
            "Epoch 2/5\n",
            "29809/60000 [=============>................] - ETA: 1:01 - loss: 0.3985 - accuracy: 0.8520"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-828f65f10b71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstart_at\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_dummy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mexec_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m \u001b[0mstart_at\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Tempo di addestramento: %d minuti e %d secondi\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexec_time\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexec_time\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Al2VriFUBLWM"
      },
      "source": [
        "Nel mio caso, l'esecuzione di 5 epoche di stochastic gradient descent ha richiesto 4 volte il tempo del full batch, ma l'addestramento si è concluso con un risultato decisamente migliore.\r\n",
        "\r\n",
        "## Mini Batch Gradient Descent\r\n",
        "\r\n",
        "questa è la versione intermedia e anche quella più consigliata da utilizzare\r\n",
        "\r\n",
        "ricreiamo e ricompiliamo il modello"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhBBiPhoBMJ8"
      },
      "source": [
        "tensorflow.random.set_seed(0\r\n",
        "                          ) #per poter riprodurrer i risultati\r\n",
        "\r\n",
        "model = Sequential()\r\n",
        "model.add(Dense(512, activation='relu', input_dim=X_train.shape[1]))\r\n",
        "model.add(Dense(256, activation='relu'))\r\n",
        "model.add(Dense(128, activation='relu'))\r\n",
        "model.add(Dense(num_classes, activation='softmax'))\r\n",
        "\r\n",
        "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKT_dfnbBkP0"
      },
      "source": [
        "all'interno del metodo fit specifichiamo la dimensione di ogni batch, i valori consigliati sono quelli in potenza di 2 quindi 32, 64, 128, 256 e 512\r\n",
        "\r\n",
        "optiamo per 512 (farò poi delle prove con i diversi valori)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pT-9CQx0BxoJ",
        "outputId": "7ead38cb-5335-48c3-f93c-945aad87142d"
      },
      "source": [
        "history = History()\r\n",
        "batch=128\r\n",
        "\r\n",
        "\"\"\"\r\n",
        "128 8 minuti e 17 secondi - loss: 0.1460 - accuracy: 0.9498\r\n",
        "256 6 minuti e 38 secondi - loss: 0.2308 - accuracy: 0.9187\r\n",
        "512 5 minuti e 53 secondi - loss: 0.3057 - accuracy: 0.8917\r\n",
        "\"\"\"\r\n",
        "\r\n",
        "start_at= time()\r\n",
        "model.fit(X_train, y_train_dummy, epochs=100, batch_size=batch, callbacks=[history])\r\n",
        "exec_time = time() - start_at\r\n",
        "\r\n",
        "print(\"Tempo di addestramento: %d minuti e %d secondi\" % (exec_time/60, exec_time%60))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 1.4487 - accuracy: 0.5730\n",
            "Epoch 2/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.6258 - accuracy: 0.7942\n",
            "Epoch 3/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.5297 - accuracy: 0.8223\n",
            "Epoch 4/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.4909 - accuracy: 0.8308\n",
            "Epoch 5/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.4642 - accuracy: 0.8380\n",
            "Epoch 6/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.4457 - accuracy: 0.8453\n",
            "Epoch 7/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.4265 - accuracy: 0.8526\n",
            "Epoch 8/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.4168 - accuracy: 0.8545\n",
            "Epoch 9/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.4093 - accuracy: 0.8561\n",
            "Epoch 10/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.3929 - accuracy: 0.8625\n",
            "Epoch 11/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.3897 - accuracy: 0.8617\n",
            "Epoch 12/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.3834 - accuracy: 0.8687\n",
            "Epoch 13/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.3772 - accuracy: 0.8674\n",
            "Epoch 14/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.3702 - accuracy: 0.8701\n",
            "Epoch 15/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.3601 - accuracy: 0.8735\n",
            "Epoch 16/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.3576 - accuracy: 0.8752\n",
            "Epoch 17/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.3502 - accuracy: 0.8771\n",
            "Epoch 18/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.3453 - accuracy: 0.8784\n",
            "Epoch 19/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.3432 - accuracy: 0.8782\n",
            "Epoch 20/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.3336 - accuracy: 0.8815\n",
            "Epoch 21/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.3349 - accuracy: 0.8822\n",
            "Epoch 22/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.3268 - accuracy: 0.8842\n",
            "Epoch 23/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.3157 - accuracy: 0.8874\n",
            "Epoch 24/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.3149 - accuracy: 0.8870\n",
            "Epoch 25/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.3144 - accuracy: 0.8869\n",
            "Epoch 26/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.3110 - accuracy: 0.8882\n",
            "Epoch 27/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.3060 - accuracy: 0.8915\n",
            "Epoch 28/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.3025 - accuracy: 0.8920\n",
            "Epoch 29/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.3041 - accuracy: 0.8916\n",
            "Epoch 30/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.3000 - accuracy: 0.8919\n",
            "Epoch 31/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.2959 - accuracy: 0.8940\n",
            "Epoch 32/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.2939 - accuracy: 0.8946\n",
            "Epoch 33/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.2917 - accuracy: 0.8969\n",
            "Epoch 34/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.2796 - accuracy: 0.9007\n",
            "Epoch 35/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.2801 - accuracy: 0.9003\n",
            "Epoch 36/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.2777 - accuracy: 0.9002\n",
            "Epoch 37/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2762 - accuracy: 0.9001\n",
            "Epoch 38/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2664 - accuracy: 0.9035\n",
            "Epoch 39/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2709 - accuracy: 0.9032\n",
            "Epoch 40/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2665 - accuracy: 0.9040\n",
            "Epoch 41/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2681 - accuracy: 0.9030\n",
            "Epoch 42/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2676 - accuracy: 0.9057\n",
            "Epoch 43/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2609 - accuracy: 0.9082\n",
            "Epoch 44/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2566 - accuracy: 0.9083\n",
            "Epoch 45/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2589 - accuracy: 0.9050\n",
            "Epoch 46/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2547 - accuracy: 0.9097\n",
            "Epoch 47/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2509 - accuracy: 0.9102\n",
            "Epoch 48/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2470 - accuracy: 0.9108\n",
            "Epoch 49/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2439 - accuracy: 0.9132\n",
            "Epoch 50/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2454 - accuracy: 0.9120\n",
            "Epoch 51/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2371 - accuracy: 0.9145\n",
            "Epoch 52/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2371 - accuracy: 0.9160\n",
            "Epoch 53/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2356 - accuracy: 0.9153\n",
            "Epoch 54/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2359 - accuracy: 0.9144\n",
            "Epoch 55/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2321 - accuracy: 0.9160\n",
            "Epoch 56/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2308 - accuracy: 0.9177\n",
            "Epoch 57/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2296 - accuracy: 0.9170\n",
            "Epoch 58/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2250 - accuracy: 0.9207\n",
            "Epoch 59/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2254 - accuracy: 0.9197\n",
            "Epoch 60/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2233 - accuracy: 0.9206\n",
            "Epoch 61/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2230 - accuracy: 0.9197\n",
            "Epoch 62/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2165 - accuracy: 0.9220\n",
            "Epoch 63/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2132 - accuracy: 0.9220\n",
            "Epoch 64/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2088 - accuracy: 0.9252\n",
            "Epoch 65/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2158 - accuracy: 0.9227\n",
            "Epoch 66/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2050 - accuracy: 0.9263\n",
            "Epoch 67/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2027 - accuracy: 0.9265\n",
            "Epoch 68/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2063 - accuracy: 0.9274\n",
            "Epoch 69/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1986 - accuracy: 0.9301\n",
            "Epoch 70/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1972 - accuracy: 0.9306\n",
            "Epoch 71/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1946 - accuracy: 0.9309\n",
            "Epoch 72/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2007 - accuracy: 0.9286\n",
            "Epoch 73/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1919 - accuracy: 0.9312\n",
            "Epoch 74/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1957 - accuracy: 0.9294\n",
            "Epoch 75/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1918 - accuracy: 0.9325\n",
            "Epoch 76/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1876 - accuracy: 0.9323\n",
            "Epoch 77/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1888 - accuracy: 0.9326\n",
            "Epoch 78/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1851 - accuracy: 0.9347\n",
            "Epoch 79/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1871 - accuracy: 0.9335\n",
            "Epoch 80/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1839 - accuracy: 0.9344\n",
            "Epoch 81/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1806 - accuracy: 0.9351\n",
            "Epoch 82/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1788 - accuracy: 0.9365\n",
            "Epoch 83/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1775 - accuracy: 0.9368\n",
            "Epoch 84/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1768 - accuracy: 0.9381\n",
            "Epoch 85/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1686 - accuracy: 0.9415\n",
            "Epoch 86/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1698 - accuracy: 0.9399\n",
            "Epoch 87/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1676 - accuracy: 0.9400\n",
            "Epoch 88/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1646 - accuracy: 0.9411\n",
            "Epoch 89/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1686 - accuracy: 0.9400\n",
            "Epoch 90/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1625 - accuracy: 0.9427\n",
            "Epoch 91/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1629 - accuracy: 0.9436\n",
            "Epoch 92/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1619 - accuracy: 0.9436\n",
            "Epoch 93/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1599 - accuracy: 0.9435\n",
            "Epoch 94/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1571 - accuracy: 0.9439\n",
            "Epoch 95/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1559 - accuracy: 0.9457\n",
            "Epoch 96/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1555 - accuracy: 0.9465\n",
            "Epoch 97/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1518 - accuracy: 0.9469\n",
            "Epoch 98/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1528 - accuracy: 0.9462\n",
            "Epoch 99/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1525 - accuracy: 0.9459\n",
            "Epoch 100/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1460 - accuracy: 0.9498\n",
            "Tempo di addestramento: 8 minuti e 17 secondi\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWVFPRNPDf6z"
      },
      "source": [
        "il mini batch con size di 512 ha richiesto poco piu tempo del full ma ha portato a un risultato estremamente migliore\r\n",
        "\r\n",
        "visualizziamo sul grafico la variazione dell'errore ad ogni epoca\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rNsU9ckDpTc"
      },
      "source": [
        "plt.figure(figsize=(14,10))\r\n",
        "plt.title(\"Mini Batch gradient Descent - Batch Size = 512\")\r\n",
        "plt.xlabel(\"Epoca\")\r\n",
        "plt.ylabel(\"Log-Loss\")\r\n",
        "plt.plot(history.history['loss'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDiYYV7BD-jT"
      },
      "source": [
        "l'errore si è ridotto molto in fretta durante le prime 10 epoche, dopodichè ha continuato a migliorare più lentamento oscillando leggermente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0JOCrM0D7EN"
      },
      "source": [
        "type(history.history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmsRNFqKEGL6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}