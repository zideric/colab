{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Gradient Descent.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMbIsKr6t18Y7ywMjdnYOzX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zideric/colab/blob/main/Gradient_Descent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_g_zsZKB-0qF"
      },
      "source": [
        "# Stochastic, Mini batch e Full batch Gradient Descent\n",
        "\n",
        "vediamo le tre varianti dell'algoritmo di ottimizzazione\n",
        "\n",
        "* **Full Batch:** utilizza tutti gli esempi per correggere i coefficienti\n",
        "* **Stochasti:** un solo esempio per volta per correggere i coefficienti\n",
        "* **Mini Batch:** utilizza un determinato numero di esempio per volta per correggere i coefficienti\n",
        "\n",
        "utilizziamo il [Fashion MNIST dataset](https://github.com/zalandoresearch/fashion-mnist), contiene capi di abbigliamento corrrettamente classificati, creato da Zalando\n",
        "\n",
        "Importiamo i moduli"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKQFRiVI_d1g"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "from time import time\n",
        "\n",
        "#definisco la funzione di profession AI per poter riprodurre i risultati in questo notebook\n",
        "\n",
        "def set_seed(seed):\n",
        "    from os import environ\n",
        "    environ[\"PYTHONHASHSEED\"] = '0'\n",
        "    environ[\"CUDA_VISIBLE_DEVICES\"]='-1'\n",
        "    environ[\"TF_CUDNN_USE_AUTOTUNE\"] ='0'\n",
        "\n",
        "    from numpy.random import seed as np_seed\n",
        "    np_seed(seed)\n",
        "    import random\n",
        "    random.seed(seed)\n",
        "    from tensorflow import set_random_seed\n",
        "    set_random_seed(seed)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTeGA9WxACYW"
      },
      "source": [
        "## Preparazione dei dati\n",
        "\n",
        "carichiamo il dataset direttamente da Keras."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lq-VAny2_82r",
        "outputId": "fc43e6be-db02-49dc-8917-c826b4261449"
      },
      "source": [
        "from keras.datasets import fashion_mnist\n",
        "\n",
        "labels = [\"T-shirt/top\",\"Pantalone\",\"Pullover\",\"Vestito\",\"Cappotto\",\"Sandalo\",\"Maglietta\",\"Sneaker\",\"Borsa\",\"Stivaletto\"]\n",
        "\n",
        "(X_train, y_train),(X_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "print(\"Numero di proprieta: \" + str(X_train.shape[1]))\n",
        "print(\"Esempi di training: \" + str(X_train.shape[0]))\n",
        "print(\"Esempi di test: \" + str(X_test.shape[0]))\n",
        "\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Numero di proprieta: 28\n",
            "Esempi di training: 60000\n",
            "Esempi di test: 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHSZ0U4hBA-5"
      },
      "source": [
        "l'immagine è rappresentata da una matrice di 28*28 pixel\n",
        "visualizziamone una"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "NrkL27g9AiA2",
        "outputId": "70ee05d1-168f-4913-92ef-2773605bc5f1"
      },
      "source": [
        "plt.axis(\"off\") \n",
        "plt.imshow(X_train[1],cmap=\"gray\")\n",
        "print(\"L'immagine raffigura un/o %s\" % labels[y_train[1]])\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "L'immagine raffigura un/o T-shirt/top\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6GyE-VhB07a"
      },
      "source": [
        "visto che ogni singolo elemmento (osservazione) è una matrice 28*28 dobbiamo convertire questa matrice in un singolo vettore da dare in input al modello. Usiamo reshape (al contrario del solito per visualizzare immagine)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgRxKrQzCR8B",
        "outputId": "8cf334bd-5bbd-40e9-b448-a2e0944949ac"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3_gjf6RAurb",
        "outputId": "1aa23562-b8fe-4385-ec43-198ef7f79fe8"
      },
      "source": [
        "X_train = X_train.reshape(X_train.shape[0],28*28)\n",
        "X_test = X_test.reshape(X_test.shape[0],28*28)\n",
        "\n",
        "X_train.shape"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 784)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZ03ecBcCgwV"
      },
      "source": [
        "standardizziamo i valori, anche in questo caso ci basta dividere ogni valore per 255 visto che 255 è il valore massimo e 0 il valore minimo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hiqghcJcBolV"
      },
      "source": [
        "X_train = X_train/255\n",
        "X_test = X_test/255"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9POewYntCv2m"
      },
      "source": [
        "Gli array con i target contengono un valore numerico che va da 0 a 9, questo numero rappresenta la categoria di appartenenza del prodotto.\n",
        "per poter eseguire la classificazione multiclasse dobbiamo crare 10 variabili dumm per ogni osservaizone, una per ogni classe, quella con il valore 1 sarà la classe identificata dal modelllo (creiamo un array di 10 elementi per ogni target)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5uiPbV5Csep"
      },
      "source": [
        "from keras.utils import to_categorical\n",
        "\n",
        "num_classes = 10\n",
        "\n",
        "y_train_dummy = to_categorical(y_train, num_classes)\n",
        "y_test_dumyy = to_categorical(y_test, num_classes)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxGVlszjDSwk"
      },
      "source": [
        "## Full batch\n",
        "\n",
        "creiamo il modello, usiamo la stessa architettura del notebook precedente"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8PW3UaqFcF_"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "from time import time\n",
        "\n",
        "#definisco la funzione di profession AI per poter riprodurre i risultati in questo notebook\n",
        "\n",
        "def set_seed(seed):\n",
        "    from os import environ\n",
        "    environ[\"PYTHONHASHSEED\"] = '0'\n",
        "    environ[\"CUDA_VISIBLE_DEVICES\"]='-1'\n",
        "    environ[\"TF_CUDNN_USE_AUTOTUNE\"] ='0'\n",
        "\n",
        "    from numpy.random import seed as np_seed\n",
        "    np_seed(seed)\n",
        "    import random\n",
        "    random.seed(seed)\n",
        "    from tensorflow import set_random_seed\n",
        "    set_random_seed(seed)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1qodKfSFbKQ"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "from time import time\n",
        "\n",
        "#definisco la funzione di profession AI per poter riprodurre i risultati in questo notebook\n",
        "\n",
        "def set_seed(seed):\n",
        "    from os import environ\n",
        "    environ[\"PYTHONHASHSEED\"] = '0'\n",
        "    environ[\"CUDA_VISIBLE_DEVICES\"]='-1'\n",
        "    environ[\"TF_CUDNN_USE_AUTOTUNE\"] ='0'\n",
        "\n",
        "    from numpy.random import seed as np_seed\n",
        "    np_seed(seed)\n",
        "    import random\n",
        "    random.seed(seed)\n",
        "    from tensorflow import set_random_seed\n",
        "    set_random_seed(seed)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcg6kXjTDQ0b"
      },
      "source": [
        "#set_seed(0)  #peer riprodurre i risultati come il corso\n",
        "import tensorflow\n",
        "tensorflow.random.set_seed(0\n",
        "                           )\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(512, activation='relu', input_dim=X_train.shape[1]))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(num_classes, activation='softmax')) #neurone di optput mettiamo softmax\n"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcik4eUrD1Hv",
        "outputId": "8d24e7bd-bac2-48aa-8526-fc003cbc34fe"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_8 (Dense)              (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 567,434\n",
            "Trainable params: 567,434\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uev83n3cD8xf"
      },
      "source": [
        "sono oltre mezzo milione di parametri. Utilizziamo il metodo compile per preparare il modello per l'addestramento. \n",
        "Come ottimizzatore usiamo sempre lo stochastic (sgd, vediamo perche bisogna specificare sempre questo anche se vogliamo full batch)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLrWIDTSD7V1"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='sgd',metrics=['accuracy'])"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qyVLs_DpEao9"
      },
      "source": [
        "Adesso, per utilizzare il full batch gradient descent, non dobbiamo far altro che specificare all'interno del metodo fit che la dimensione di un batch deve essere pari al numero di osservazioni nel set di addestramento, in tal modo l'algoritmo di ottimizzazione utilizzerà un unico batch con tutte le osservazioni ad ogni iterazione del gradient descent.\n",
        "Per poter costruire un grafico della funzione di costo ad ogni epoca dobbiamo tener traccia di questi valori, per farlo dobbiamo definire un callback."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3CxiBoLEWqT",
        "outputId": "0c60047d-c08a-4f45-c76f-c7be70cad230"
      },
      "source": [
        "from keras.callbacks import History\n",
        "\n",
        "history = History()\n",
        "\n",
        "start_at = time()\n",
        "model.fit(X_train, y_train_dummy, epochs=10, batch_size=X_train.shape[0],callbacks=[history])\n",
        "exec_time= time()-start_at\n",
        "\n",
        "print(\"Tempo di addestramento: %d minuti e %d secondi\" % (exec_time/60, exec_time%60))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1/1 [==============================] - 3s 3s/step - loss: 2.4030 - accuracy: 0.0945\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 3s 3s/step - loss: 2.3737 - accuracy: 0.0919\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 3s 3s/step - loss: 2.3477 - accuracy: 0.0898\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 3s 3s/step - loss: 2.3245 - accuracy: 0.0915\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 3s 3s/step - loss: 2.3036 - accuracy: 0.0982\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 3s 3s/step - loss: 2.2844 - accuracy: 0.1115\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 3s 3s/step - loss: 2.2665 - accuracy: 0.1303\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 3s 3s/step - loss: 2.2497 - accuracy: 0.1525\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 3s 3s/step - loss: 2.2337 - accuracy: 0.1796\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 3s 3s/step - loss: 2.2183 - accuracy: 0.2095\n",
            "Tempo di addestramento: 0 minuti e 28 secondi\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Gj0ItsKE96v"
      },
      "source": [
        ""
      ],
      "execution_count": 42,
      "outputs": []
    }
  ]
}